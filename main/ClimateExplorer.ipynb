{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Climate Explorer\n",
   "id": "bfd12172313f5dc9"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "1. Data collecting and clearing.\n",
    "\n"
   ],
   "id": "63492c7954a032b2"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Downloading data online and clearing data with python.",
   "id": "f4726b87a35bdbf2"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Saving the data as csv file so that the data can be easily used by other teammates.",
   "id": "bb6292cf28d05caa"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "(1) Changing global temperature from monthly to yearly",
   "id": "fd091b83813a9af5"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# 1. Read NASA GISS monthly temperature anomaly data (data with -.xx format will be automatically recognized as negative numbers)\n",
    "url = r\"../../csv_file/globe/original_tempera_difference.csv\"\n",
    "data = pd.read_csv(url, skiprows=1)  # Skip header row\n",
    "\n",
    "# 2. Define monthly column names (J to D correspond to January-December)\n",
    "month_columns = ['Jan', 'Feb', 'Mar', 'Apr', 'May', 'Jun', 'Jul', 'Aug', 'Sep', 'Oct', 'Nov', 'Dec']\n",
    "\n",
    "# 3. Data preprocessing: Handle possible missing values and convert to numeric type\n",
    "data[month_columns] = data[month_columns].replace('***', np.nan)  # Replace missing value markers\n",
    "data[month_columns] = data[month_columns].astype(float)  # Convert to float\n",
    "\n",
    "# 4. Calculate monthly absolute temperature (anomaly value + 13.9)\n",
    "month_abs_columns = [f'{month}_Abs' for month in month_columns]  # Define monthly absolute temperature column names\n",
    "data[month_abs_columns] = data[month_columns] + 13.9  # Generate monthly absolute temperatures\n",
    "\n",
    "# 5. Calculate annual absolute temperature statistics\n",
    "data['Annual_Mean_Absolute'] = data[month_abs_columns].mean(axis=1)    # Annual absolute temperature mean\n",
    "data['Annual_Median_Absolute'] = data[month_abs_columns].median(axis=1)# Annual absolute temperature median\n",
    "data['Annual_Std_Absolute'] = data[month_abs_columns].std(axis=1)      # Annual absolute temperature standard deviation\n",
    "\n",
    "# 6. Filter key columns (only keep year and absolute temperature statistics) and retain two decimal places uniformly\n",
    "result = data[['Year', 'Annual_Mean_Absolute', 'Annual_Median_Absolute', 'Annual_Std_Absolute']].copy()\n",
    "result = result.round(2)  # Keep two decimal places for all numeric columns\n",
    "\n",
    "# 7. Save results to CSV file\n",
    "result.to_csv('../../csv_file/globe/annual_temperature_data.csv', index=False, float_format='%.2f')\n",
    "\n",
    "# 8. Display first 10 rows of results\n",
    "print(\"Processed annual absolute temperature data (absolute temperature statistics only):\")\n",
    "print(result.head(10))"
   ],
   "id": "b7ff23d1b9d82cf0"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "(2) Collectin Global Co2's data and changing it from daily to monthly.",
   "id": "87e871b86b64cc91"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import pandas as pd\n",
    "\n",
    "# 1. Read CSV file (comma-separated by default, no need to specify sep)\n",
    "input_file = r\"../../csv_file/globe/original_co2.csv\"  # Replace with your actual file path\n",
    "df = pd.read_csv(input_file, encoding=\"utf-8\")  # Replace with \"gbk\" if an error occurs\n",
    "\n",
    "# 2. Group by \"year+month\" and calculate monthly averages of smoothed and trend (keep 2 decimal places)\n",
    "monthly_df = df.groupby(\n",
    "    by=[\"year\", \"month\"],  # Match column names in CSV header\n",
    "    as_index=False\n",
    ").agg(\n",
    "    smoothed_monthly=(\"smoothed\", lambda x: round(x.mean(), 2)),\n",
    "    trend_monthly=(\"trend\", lambda x: round(x.mean(), 2))\n",
    ")\n",
    "\n",
    "# 3. Save processed monthly data to new CSV\n",
    "output_file = \"../../csv_file/globe/final_co2_monthly.csv\"\n",
    "monthly_df.to_csv(output_file, index=False, encoding=\"utf-8\")\n",
    "\n",
    "print(f\"Monthly average data saved to: {output_file}\")\n",
    "print(\"Preview of processed data:\")\n",
    "print(monthly_df.head())"
   ],
   "id": "5775bac6292b4334"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "(3) Collecting hemisphere's temperature data, comparing south-half and north-half yearly.",
   "id": "b2cc452aab703eba"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# ---------------------- 1. Read NASA GISS monthly temperature data for Northern and Southern Hemispheres (public link) ----------------------\n",
    "nh_url = \"https://data.giss.nasa.gov/gistemp/tabledata_v3/NH.Ts+dSST.csv\"  # Northern Hemisphere\n",
    "sh_url = \"https://data.giss.nasa.gov/gistemp/tabledata_v3/SH.Ts+dSST.csv\"  # Southern Hemisphere\n",
    "\n",
    "# Read data (skip description rows)\n",
    "nh_data = pd.read_csv(nh_url, skiprows=1)\n",
    "sh_data = pd.read_csv(sh_url, skiprows=1)\n",
    "\n",
    "# ---------------------- 2. Data Preprocessing (unified logic) ----------------------\n",
    "month_columns = ['Jan', 'Feb', 'Mar', 'Apr', 'May', 'Jun', 'Jul', 'Aug', 'Sep', 'Oct', 'Nov', 'Dec']\n",
    "\n",
    "def process_hemisphere_data(data):\n",
    "    \"\"\"Process data for a single hemisphere: cleaning, calculate absolute temperature, annual statistics\"\"\"\n",
    "    data = data[['Year'] + month_columns].copy()\n",
    "    data[month_columns] = data[month_columns].replace('***', np.nan).astype(float)\n",
    "    # Calculate monthly absolute temperature\n",
    "    month_abs_cols = [f'{m}_Abs' for m in month_columns]\n",
    "    data[month_abs_cols] = data[month_columns] + 13.9\n",
    "    # Calculate annual statistics\n",
    "    data['Annual_Mean_Abs'] = data[month_abs_cols].mean(axis=1).round(2)\n",
    "    data['Annual_Median_Abs'] = data[month_abs_cols].median(axis=1).round(2)\n",
    "    data['Annual_Std_Abs'] = data[month_abs_cols].std(axis=1).round(2)\n",
    "    return data[['Year', 'Annual_Mean_Abs', 'Annual_Median_Abs', 'Annual_Std_Abs']]\n",
    "\n",
    "# Process Northern and Southern Hemisphere data\n",
    "nh_processed = process_hemisphere_data(nh_data)\n",
    "sh_processed = process_hemisphere_data(sh_data)\n",
    "\n",
    "# ---------------------- 3. Merge into comparison data (fixed order: Northern first, then Southern) ----------------------\n",
    "# Add hemisphere identifier\n",
    "nh_processed['Hemisphere'] = 'Northern'\n",
    "sh_processed['Hemisphere'] = 'Southern'\n",
    "\n",
    "# Merge data: sort by year first, then by hemisphere in fixed order (Northern first, Southern second)\n",
    "comparison_data = pd.concat([nh_processed, sh_processed], axis=0)\n",
    "# Set Hemisphere as categorical type with specified order to ensure Northern comes first when sorting\n",
    "comparison_data['Hemisphere'] = pd.Categorical(comparison_data['Hemisphere'],\n",
    "                                               categories=['Northern', 'Southern'],\n",
    "                                               ordered=True)\n",
    "# Sort by Year first, then by Hemisphere (ensuring Northern comes before Southern for the same year)\n",
    "comparison_data = comparison_data.sort_values(['Year', 'Hemisphere']).reset_index(drop=True)\n",
    "\n",
    "# ---------------------- 4. Save as comparison CSV ----------------------\n",
    "comparison_data.to_csv('south_and_north_ hemisphere_comparison.csv', index=False, float_format='%.2f')\n",
    "\n",
    "# ---------------------- 5. Display sample results ----------------------\n",
    "print(\"Annual temperature change comparison between Northern and Southern Hemispheres (sorted by year + hemisphere, first 10 rows):\")\n",
    "print(comparison_data.head(10))"
   ],
   "id": "838df68898e53866"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "(4) Collecting and clearing temperature data from different nations and regions.",
   "id": "93d858c6f7f859a7"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import pandas as pd\n",
    "\n",
    "# 1. Read CSV file\n",
    "df = pd.read_csv(\"../../csv_file/region/GlobalLandTemperaturesByCountry.csv\")\n",
    "country = \"\"\n",
    "target_country = country\n",
    "temperature_col = \"AverageTemperature\"\n",
    "\n",
    "# 2. Filter specified country + Remove missing values in temperature column\n",
    "df_filtered = df[df[\"Country\"] == target_country].dropna(subset=[temperature_col])\n",
    "\n",
    "# 3. Process date: Extract year\n",
    "df_filtered[\"dt\"] = pd.to_datetime(df_filtered[\"dt\"])\n",
    "df_filtered[\"year\"] = df_filtered[\"dt\"].dt.year\n",
    "\n",
    "# 4. Group by year, calculate statistics, and keep two decimal places\n",
    "yearly_stats = df_filtered.groupby(\"year\")[temperature_col].agg(\n",
    "    mean=\"mean\",\n",
    "    median=\"median\",\n",
    "    standard_deviation=\"std\"\n",
    ").reset_index()\n",
    "\n",
    "# 5. Keep two decimal places\n",
    "yearly_stats = yearly_stats.round(2)\n",
    "\n",
    "# Output results\n",
    "print(\"Annual temperature statistics for the specified country:\")\n",
    "print(yearly_stats)\n",
    "\n",
    "# Save as new CSV\n",
    "yearly_stats.to_csv(f\"../../csv_file/region/{country}_tempera.csv\", index=False)"
   ],
   "id": "a36e22c160576937"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "2. Visualizing the data.",
   "id": "9e4bfce8ca745af7"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "(1)",
   "id": "9e225a29252abc53"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "45130d8b4eb49e6e"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "(2)",
   "id": "e149e198ec62bf0e"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "491e53389293d38"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "(3)",
   "id": "3e5bb70eaf8ce19a"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "b3a9ed2b047a8696"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "3. Analysing the data within AI.",
   "id": "e22ae470c0d71290"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "(1)",
   "id": "3f2db8174b965b4a"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# 1. Load data\n",
    "df = pd.read_csv(\"../csv_files/GlobalLandTemperaturesByCountry.csv\")\n",
    "\n",
    "# Keep necessary columns\n",
    "df = df[['dt', 'AverageTemperature', 'Country']].dropna()\n",
    "\n",
    "# Convert date\n",
    "df['dt'] = pd.to_datetime(df['dt'])\n",
    "df['Year'] = df['dt'].dt.year\n",
    "\n",
    "# 2. Aggregate to country-level means\n",
    "country_temp = (\n",
    "    df.groupby('Country')['AverageTemperature']\n",
    "      .mean()\n",
    "      .reset_index()\n",
    ")\n",
    "\n",
    "# 3. Simulate regional CO2\n",
    "# Global baseline ~400 ppm with regional variation\n",
    "np.random.seed(42)\n",
    "country_temp['CO2'] = 400 + np.random.normal(0, 15, size=len(country_temp))\n",
    "\n",
    "# 4. Feature matrix\n",
    "X = country_temp[['AverageTemperature', 'CO2']]\n",
    "\n",
    "# Standardize for K-Means\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# 5. Apply K-Means clustering\n",
    "kmeans = KMeans(n_clusters=4, random_state=42)\n",
    "country_temp['Cluster'] = kmeans.fit_predict(X_scaled)\n",
    "\n",
    "# 6. Visualization\n",
    "plt.figure(figsize=(8,6))\n",
    "plt.scatter(\n",
    "    country_temp['AverageTemperature'],\n",
    "    country_temp['CO2'],\n",
    "    c=country_temp['Cluster']\n",
    ")\n",
    "plt.xlabel(\"Average Temperature (°C)\")\n",
    "plt.ylabel(\"Simulated CO₂ (ppm)\")\n",
    "plt.title(\"Climate Clusters Based on Temperature and CO₂\")\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "# 7. Display output\n",
    "print(country_temp.head())"
   ],
   "id": "f41d61ea52f36335"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "(2)",
   "id": "2d1c749a29c4872e"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# 1. Load data\n",
    "annual_temp = pd.read_csv(\"../csv_files/annual_temperature_data.csv\")\n",
    "co2 = pd.read_csv(\"../csv_files/final_co2_monthly.csv\")\n",
    "global_temp = pd.read_csv(\"../csv_files/GlobalLandTemperaturesByCountry.csv\")\n",
    "\n",
    "# 2. Preprocess global temperature data\n",
    "global_temp = global_temp[['dt', 'AverageTemperature', 'Country']].dropna()\n",
    "global_temp['dt'] = pd.to_datetime(global_temp['dt'])\n",
    "global_temp['Year'] = global_temp['dt'].dt.year\n",
    "\n",
    "# Country-level annual mean temperature\n",
    "country_annual_temp = (\n",
    "    global_temp.groupby(['Country', 'Year'])['AverageTemperature']\n",
    "    .mean()\n",
    "    .reset_index()\n",
    ")\n",
    "\n",
    "# 3. Preprocess CO2 data\n",
    "co2_annual = (\n",
    "    co2.groupby('year')['smoothed_monthly']\n",
    "    .mean()\n",
    "    .reset_index()\n",
    "    .rename(columns={'year': 'Year', 'smoothed_monthly': 'CO2'})\n",
    ")\n",
    "\n",
    "# 4. Merge datasets\n",
    "merged = country_annual_temp.merge(co2_annual, on='Year', how='left')\n",
    "\n",
    "# Merge with final annual temperature data if Year exists\n",
    "if 'Year' in annual_temp.columns:\n",
    "    merged = merged.merge(\n",
    "        annual_temp,\n",
    "        on='Year',\n",
    "        how='left',\n",
    "        suffixes=('_Country', '_Global')\n",
    "    )\n",
    "\n",
    "# 5. Select numeric features\n",
    "numeric_df = merged.select_dtypes(include=['float64', 'int64'])\n",
    "\n",
    "print(\"Numeric features included in correlation analysis:\")\n",
    "print(numeric_df.columns)\n",
    "\n",
    "# 6. Compute correlation\n",
    "correlation_matrix = numeric_df.corr()\n",
    "\n",
    "print(\"\\nCorrelation Matrix:\")\n",
    "print(correlation_matrix)\n",
    "\n",
    "# 7. Visualization\n",
    "plt.figure(figsize=(11, 8))\n",
    "sns.heatmap(\n",
    "    correlation_matrix,\n",
    "    annot=True,\n",
    "    fmt=\".2f\",\n",
    "    cmap=\"coolwarm\",\n",
    "    square=True\n",
    ")\n",
    "plt.title(\"Correlation Analysis: Temperature, CO₂, and Time\")\n",
    "plt.show()"
   ],
   "id": "c59f1c6f2153df2b"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "(3)",
   "id": "fedc11594098c199"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "5e96c494a848d718"
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
