{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "1.Data collecting and clearing.\n",
    "Downloading data online and clearing data with python.\n",
    "Saving the data as csv file so that the data can be easily used by other teammates."
   ],
   "id": "bfd12172313f5dc9"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "(1) Changing global temperature from monthly to yearly",
   "id": "fd091b83813a9af5"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# 1. Read NASA GISS monthly temperature anomaly data (data with -.xx format will be automatically recognized as negative numbers)\n",
    "url = r\"../../csv_file/globe/original_tempera_difference.csv\"\n",
    "data = pd.read_csv(url, skiprows=1)  # Skip header row\n",
    "\n",
    "# 2. Define monthly column names (J to D correspond to January-December)\n",
    "month_columns = ['Jan', 'Feb', 'Mar', 'Apr', 'May', 'Jun', 'Jul', 'Aug', 'Sep', 'Oct', 'Nov', 'Dec']\n",
    "\n",
    "# 3. Data preprocessing: Handle possible missing values and convert to numeric type\n",
    "data[month_columns] = data[month_columns].replace('***', np.nan)  # Replace missing value markers\n",
    "data[month_columns] = data[month_columns].astype(float)  # Convert to float\n",
    "\n",
    "# 4. Calculate monthly absolute temperature (anomaly value + 13.9)\n",
    "month_abs_columns = [f'{month}_Abs' for month in month_columns]  # Define monthly absolute temperature column names\n",
    "data[month_abs_columns] = data[month_columns] + 13.9  # Generate monthly absolute temperatures\n",
    "\n",
    "# 5. Calculate annual absolute temperature statistics\n",
    "data['Annual_Mean_Absolute'] = data[month_abs_columns].mean(axis=1)    # Annual absolute temperature mean\n",
    "data['Annual_Median_Absolute'] = data[month_abs_columns].median(axis=1)# Annual absolute temperature median\n",
    "data['Annual_Std_Absolute'] = data[month_abs_columns].std(axis=1)      # Annual absolute temperature standard deviation\n",
    "\n",
    "# 6. Filter key columns (only keep year and absolute temperature statistics) and retain two decimal places uniformly\n",
    "result = data[['Year', 'Annual_Mean_Absolute', 'Annual_Median_Absolute', 'Annual_Std_Absolute']].copy()\n",
    "result = result.round(2)  # Keep two decimal places for all numeric columns\n",
    "\n",
    "# 7. Save results to CSV file\n",
    "result.to_csv('../../csv_file/globe/annual_temperature_data.csv', index=False, float_format='%.2f')\n",
    "\n",
    "# 8. Display first 10 rows of results\n",
    "print(\"Processed annual absolute temperature data (absolute temperature statistics only):\")\n",
    "print(result.head(10))"
   ],
   "id": "b7ff23d1b9d82cf0"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "(2)Collectin Global Co2's data and changing it from daily to monthly.",
   "id": "87e871b86b64cc91"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import pandas as pd\n",
    "\n",
    "# 1. Read CSV file (comma-separated by default, no need to specify sep)\n",
    "input_file = r\"../../csv_file/globe/original_co2.csv\"  # Replace with your actual file path\n",
    "df = pd.read_csv(input_file, encoding=\"utf-8\")  # Replace with \"gbk\" if an error occurs\n",
    "\n",
    "# 2. Group by \"year+month\" and calculate monthly averages of smoothed and trend (keep 2 decimal places)\n",
    "monthly_df = df.groupby(\n",
    "    by=[\"year\", \"month\"],  # Match column names in CSV header\n",
    "    as_index=False\n",
    ").agg(\n",
    "    smoothed_monthly=(\"smoothed\", lambda x: round(x.mean(), 2)),\n",
    "    trend_monthly=(\"trend\", lambda x: round(x.mean(), 2))\n",
    ")\n",
    "\n",
    "# 3. Save processed monthly data to new CSV\n",
    "output_file = \"../../csv_file/globe/final_co2_monthly.csv\"\n",
    "monthly_df.to_csv(output_file, index=False, encoding=\"utf-8\")\n",
    "\n",
    "print(f\"Monthly average data saved to: {output_file}\")\n",
    "print(\"Preview of processed data:\")\n",
    "print(monthly_df.head())"
   ],
   "id": "5775bac6292b4334"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "(3)Collecting hemisphere's temperature data, comparing south-half and north-half yearly.",
   "id": "b2cc452aab703eba"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# ---------------------- 1. Read NASA GISS monthly temperature data for Northern and Southern Hemispheres (public link) ----------------------\n",
    "nh_url = \"https://data.giss.nasa.gov/gistemp/tabledata_v3/NH.Ts+dSST.csv\"  # Northern Hemisphere\n",
    "sh_url = \"https://data.giss.nasa.gov/gistemp/tabledata_v3/SH.Ts+dSST.csv\"  # Southern Hemisphere\n",
    "\n",
    "# Read data (skip description rows)\n",
    "nh_data = pd.read_csv(nh_url, skiprows=1)\n",
    "sh_data = pd.read_csv(sh_url, skiprows=1)\n",
    "\n",
    "# ---------------------- 2. Data Preprocessing (unified logic) ----------------------\n",
    "month_columns = ['Jan', 'Feb', 'Mar', 'Apr', 'May', 'Jun', 'Jul', 'Aug', 'Sep', 'Oct', 'Nov', 'Dec']\n",
    "\n",
    "def process_hemisphere_data(data):\n",
    "    \"\"\"Process data for a single hemisphere: cleaning, calculate absolute temperature, annual statistics\"\"\"\n",
    "    data = data[['Year'] + month_columns].copy()\n",
    "    data[month_columns] = data[month_columns].replace('***', np.nan).astype(float)\n",
    "    # Calculate monthly absolute temperature\n",
    "    month_abs_cols = [f'{m}_Abs' for m in month_columns]\n",
    "    data[month_abs_cols] = data[month_columns] + 13.9\n",
    "    # Calculate annual statistics\n",
    "    data['Annual_Mean_Abs'] = data[month_abs_cols].mean(axis=1).round(2)\n",
    "    data['Annual_Median_Abs'] = data[month_abs_cols].median(axis=1).round(2)\n",
    "    data['Annual_Std_Abs'] = data[month_abs_cols].std(axis=1).round(2)\n",
    "    return data[['Year', 'Annual_Mean_Abs', 'Annual_Median_Abs', 'Annual_Std_Abs']]\n",
    "\n",
    "# Process Northern and Southern Hemisphere data\n",
    "nh_processed = process_hemisphere_data(nh_data)\n",
    "sh_processed = process_hemisphere_data(sh_data)\n",
    "\n",
    "# ---------------------- 3. Merge into comparison data (fixed order: Northern first, then Southern) ----------------------\n",
    "# Add hemisphere identifier\n",
    "nh_processed['Hemisphere'] = 'Northern'\n",
    "sh_processed['Hemisphere'] = 'Southern'\n",
    "\n",
    "# Merge data: sort by year first, then by hemisphere in fixed order (Northern first, Southern second)\n",
    "comparison_data = pd.concat([nh_processed, sh_processed], axis=0)\n",
    "# Set Hemisphere as categorical type with specified order to ensure Northern comes first when sorting\n",
    "comparison_data['Hemisphere'] = pd.Categorical(comparison_data['Hemisphere'],\n",
    "                                               categories=['Northern', 'Southern'],\n",
    "                                               ordered=True)\n",
    "# Sort by Year first, then by Hemisphere (ensuring Northern comes before Southern for the same year)\n",
    "comparison_data = comparison_data.sort_values(['Year', 'Hemisphere']).reset_index(drop=True)\n",
    "\n",
    "# ---------------------- 4. Save as comparison CSV ----------------------\n",
    "comparison_data.to_csv('south_and_north_ hemisphere_comparison.csv', index=False, float_format='%.2f')\n",
    "\n",
    "# ---------------------- 5. Display sample results ----------------------\n",
    "print(\"Annual temperature change comparison between Northern and Southern Hemispheres (sorted by year + hemisphere, first 10 rows):\")\n",
    "print(comparison_data.head(10))"
   ],
   "id": "838df68898e53866"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "(4)Collecting and clearing temperature data from different nations and regions.",
   "id": "93d858c6f7f859a7"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import pandas as pd\n",
    "\n",
    "# 1. Read CSV file\n",
    "df = pd.read_csv(\"../../csv_file/region/GlobalLandTemperaturesByCountry.csv\")\n",
    "country = \"\"\n",
    "target_country = country\n",
    "temperature_col = \"AverageTemperature\"\n",
    "\n",
    "# 2. Filter specified country + Remove missing values in temperature column\n",
    "df_filtered = df[df[\"Country\"] == target_country].dropna(subset=[temperature_col])\n",
    "\n",
    "# 3. Process date: Extract year\n",
    "df_filtered[\"dt\"] = pd.to_datetime(df_filtered[\"dt\"])\n",
    "df_filtered[\"year\"] = df_filtered[\"dt\"].dt.year\n",
    "\n",
    "# 4. Group by year, calculate statistics, and keep two decimal places\n",
    "yearly_stats = df_filtered.groupby(\"year\")[temperature_col].agg(\n",
    "    mean=\"mean\",\n",
    "    median=\"median\",\n",
    "    standard_deviation=\"std\"\n",
    ").reset_index()\n",
    "\n",
    "# 5. Keep two decimal places\n",
    "yearly_stats = yearly_stats.round(2)\n",
    "\n",
    "# Output results\n",
    "print(\"Annual temperature statistics for the specified country:\")\n",
    "print(yearly_stats)\n",
    "\n",
    "# Save as new CSV\n",
    "yearly_stats.to_csv(f\"../../csv_file/region/{country}_tempera.csv\", index=False)"
   ],
   "id": "a36e22c160576937"
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
